{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw8_seq2seq_original_for_rhythm_baseline_3rd_version.ipynb","provenance":[{"file_id":"1nY_6uEl_SkmXCX_yREf1pAm1vat4kUCM","timestamp":1591000286093},{"file_id":"17nV8j0GDR-fRhWUybvdWW5WunsFLTm8p","timestamp":1590821256668},{"file_id":"1Fi3e-RuxcbK-7KoSLunHiXuh2fg-bC7c","timestamp":1590820572910},{"file_id":"12rimnbO6QctIqX-bPod3ohZREUvRS1QU","timestamp":1590589920298},{"file_id":"11iwJbQv9iScRo6kGP7YfyHaaorlHhzMT","timestamp":1590580416379}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WdkAyb0Rs6bW","colab_type":"text"},"source":["#**Homework 8 - Sequence-to-sequence**\n","\n","若有任何問題，歡迎來信至助教信箱 ntu-ml-2020spring-ta@googlegroups.com"]},{"cell_type":"markdown","metadata":{"id":"HJhsqjBlIiP0","colab_type":"text"},"source":["# Sequence-to-Sequence 介紹\n","- 大多數常見的 **sequence-to-sequence (seq2seq) model** 為 **encoder-decoder model**，主要由兩個部分組成，分別是 **Encoder** 和 **Decoder**，而這兩個部分則大多使用 **recurrent neural network (RNN)** 來實作，主要是用來解決輸入和輸出的長度不一樣的情況\n","- **Encoder** 是將**一連串**的輸入，如文字、影片、聲音訊號等，編碼為**單個向量**，這單個向量可以想像為是整個輸入的抽象表示，包含了整個輸入的資訊\n","- **Decoder** 是將 Encoder 輸出的單個向量逐步解碼，**一次輸出一個結果**，直到將最後目標輸出被產生出來為止，每次輸出會影響下一次的輸出，一般會在開頭加入 \"< BOS >\" 來表示開始解碼，會在結尾輸出 \"< EOS >\" 來表示輸出結束\n","\n","\n","![seq2seq](https://i.imgur.com/0zeDyuI.png)"]},{"cell_type":"markdown","metadata":{"id":"BX2vLCiYuq6a","colab_type":"text"},"source":["# 下載和引入需要的 libraries"]},{"cell_type":"code","metadata":{"id":"KKShudDCiySL","colab_type":"code","colab":{}},"source":["%%capture\n","!pip3 install --user nltk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"skJCdcXBi5b5","colab_type":"code","colab":{}},"source":["%%capture\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torch.utils.data.sampler as sampler\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","import numpy as np\n","import sys\n","import os\n","import random\n","import json\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 判斷是用 CPU 還是 GPU 執行運算\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-Irl7IluxMT","colab_type":"text"},"source":["# 資料結構"]},{"cell_type":"markdown","metadata":{"id":"VJb3zc-zwkd6","colab_type":"text"},"source":["## 定義資料的轉換\n","- 將不同長度的答案拓展到相同長度，以便訓練模型"]},{"cell_type":"code","metadata":{"id":"42Iggb94rKcI","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","class LabelTransform(object):\n","  def __init__(self, size, pad):\n","    self.size = size\n","    self.pad = pad\n","\n","  def __call__(self, label):\n","    label = np.pad(label, (0, (self.size - label.shape[0])), mode='constant', constant_values=self.pad)\n","    return label\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uypors6r4zD","colab_type":"code","colab":{}},"source":["import re\n","import json\n","import pickle\n","\n","class EN2CNDataset(data.Dataset):\n","  def __init__(self, root, max_output_len, set_name):\n","    self.root = root\n","    self.max_output_len = max_output_len\n","    self.word2int, self.int2word = self.get_dictionary()\n","\n","    # 載入資料\n","    self.data = []\n","    with open(os.path.join(self.root, f'{set_name}'), \"rb\") as f:\n","      self.data=pickle.load(f)\n","    print (f'{set_name} dataset size: {len(self.data)}')\n","\n","    self.vocab_size = len(self.word2int)\n","\n","    self.transform = LabelTransform(max_output_len, self.word2int['<PAD>'])\n","\n","  def get_dictionary(self):\n","    # 載入字典\n","    with open(os.path.join(self.root, f'vocab_word2int.json'), \"r\") as f:\n","      word2int = json.load(f)\n","    with open(os.path.join(self.root, f'vocab_int2word.json'), \"r\") as f:\n","      int2word = json.load(f)\n","    return word2int, int2word\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, Index, pad=False):\n","    global device\n","    sentence = self.data[Index]\n","    sentence_idx = []\n","    for word in sentence:\n","        if (word in self.word2int.keys()):\n","            sentence_idx.append(self.word2int[word])\n","        else:#如果遇到不会的单词就赋给不知道\n","            sentence_idx.append(self.word2int[\"<UNK>\"])\n","    if pad:\n","        sentence_idx = np.asarray(sentence_idx)\n","        sentence_idx = self.transform(sentence_idx)\n","\n","    sentence_idx = torch.LongTensor(sentence_idx).to(device)\n","    target = sentence_idx.clone()\n","    return sentence_idx, target\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WJIsNSRCyNA9","colab_type":"text"},"source":["# 模型架構"]},{"cell_type":"markdown","metadata":{"id":"3p1ZcU5HyO73","colab_type":"text"},"source":["## Encoder\n","- seq2seq模型的編碼器為RNN。 對於每個輸入，，**Encoder** 會輸出**一個向量**和**一個隱藏狀態(hidden state)**，並將隱藏狀態用於下一個輸入，換句話說，**Encoder** 會逐步讀取輸入序列，並輸出單個矢量（最終隱藏狀態）\n","- 參數:\n","  - en_vocab_size 是英文字典的大小，也就是英文的 subword 的個數\n","  - emb_dim 是 embedding 的維度，主要將 one-hot vector 的單詞向量壓縮到指定的維度，主要是為了降維和濃縮資訊的功用，可以使用預先訓練好的 word embedding，如 Glove 和 word2vector\n","  - hid_dim 是 RNN 輸出和隱藏狀態的維度\n","  - n_layers 是 RNN 要疊多少層\n","  - dropout 是決定有多少的機率會將某個節點變為 0，主要是為了防止 overfitting ，一般來說是在訓練時使用，測試時則不使用\n","- Encoder 的輸入和輸出:\n","  - 輸入: \n","    - 英文的整數序列 e.g. 1, 28, 29, 205, 2\n","  - 輸出: \n","    - outputs: 最上層 RNN 全部的輸出，可以用 Attention 再進行處理\n","    - hidden: 每層最後的隱藏狀態，將傳遞到 Decoder 進行解碼\n"]},{"cell_type":"code","metadata":{"id":"l6uNIKqvgb9J","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","  def __init__(self, vocab_size, emb_dim, hid_dim, n_layers, dropout):\n","    super().__init__()\n","    self.embedding = nn.Embedding(vocab_size, emb_dim)\n","    self.hid_dim = hid_dim\n","    self.n_layers = n_layers\n","    self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, input):\n","    # input = [batch size, sequence len]\n","    embedding = self.embedding(input)\n","    outputs, hidden = self.rnn(self.dropout(embedding))\n","    # outputs = [batch size, sequence len, hid dim * directions]\n","    # hidden =  [num_layers * directions, batch size  , hid dim]\n","    # outputs 是最上層RNN的輸出\n","        \n","    return outputs, hidden\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5maDs7wpyRE3","colab_type":"text"},"source":["## Decoder\n","- **Decoder** 是另一個 RNN，在最簡單的 seq2seq decoder 中，僅使用 **Encoder** 每一層最後的隱藏狀態來進行解碼，而這最後的隱藏狀態有時被稱為 “content vector”，因為可以想像它對整個前文序列進行編碼， 此 “content vector” 用作 **Decoder** 的**初始**隱藏狀態， 而 **Encoder** 的輸出通常用於 Attention Mechanism\n","- 參數\n","  - en_vocab_size 是英文字典的大小，也就是英文的 subword 的個數\n","  - emb_dim 是 embedding 的維度，是用來將 one-hot vector 的單詞向量壓縮到指定的維度，主要是為了降維和濃縮資訊的功用，可以使用預先訓練好的 word embedding，如 Glove 和 word2vector\n","  - hid_dim 是 RNN 輸出和隱藏狀態的維度\n","  - output_dim 是最終輸出的維度，一般來說是將 hid_dim 轉到 one-hot vector 的單詞向量\n","  - n_layers 是 RNN 要疊多少層\n","  - dropout 是決定有多少的機率會將某個節點變為0，主要是為了防止 overfitting ，一般來說是在訓練時使用，測試時則不用\n","  - isatt 是來決定是否使用 Attention Mechanism\n","\n","- Decoder 的輸入和輸出:\n","  - 輸入:\n","    - 前一次解碼出來的單詞的整數表示\n","  - 輸出:\n","    - hidden: 根據輸入和前一次的隱藏狀態，現在的隱藏狀態更新的結果\n","    - output: 每個字有多少機率是這次解碼的結果"]},{"cell_type":"code","metadata":{"id":"QTXRCkoug3ut","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","  def __init__(self, vocab_size, emb_dim, hid_dim, n_layers, dropout, isatt):\n","    super().__init__()\n","    self.vocab_size = vocab_size\n","    self.hid_dim = hid_dim * 2\n","    self.n_layers = n_layers\n","    self.embedding = nn.Embedding(vocab_size, config.emb_dim)\n","    self.isatt = isatt\n","    self.attention = Attention(hid_dim)\n","    # 如果使用 Attention Mechanism 會使得輸入維度變化，請在這裡修改\n","    # e.g. Attention 接在輸入後面會使得維度變化，所以輸入維度改為\n","    # self.input_dim = emb_dim + hid_dim * 2 if isatt else emb_dim\n","    self.input_dim = emb_dim\n","    self.rnn = nn.GRU(self.input_dim, self.hid_dim, self.n_layers, dropout = dropout, batch_first=True)\n","    self.embedding2vocab1 = nn.Linear(self.hid_dim, self.hid_dim * 2)\n","    self.embedding2vocab2 = nn.Linear(self.hid_dim * 2, self.hid_dim * 4)\n","    self.embedding2vocab3 = nn.Linear(self.hid_dim * 4, self.vocab_size)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, input, hidden, encoder_outputs):\n","    # input = [batch size, vocab size]\n","    # hidden = [batch size, n layers * directions, hid dim]\n","    # Decoder 只會是單向，所以 directions=1\n","    input = input.unsqueeze(1)\n","    embedded = self.dropout(self.embedding(input))\n","    # embedded = [batch size, 1, emb dim]\n","    if self.isatt:\n","      attn = self.attention(encoder_outputs, hidden)\n","      # TODO: 在這裡決定如何使用 Attention，e.g. 相加 或是 接在後面， 請注意維度變化\n","    output, hidden = self.rnn(embedded, hidden)\n","    # output = [batch size, 1, hid dim]\n","    # hidden = [num_layers, batch size, hid dim]\n","\n","    # 將 RNN 的輸出轉為每個詞出現的機率\n","    output = self.embedding2vocab1(output.squeeze(1))\n","    output = self.embedding2vocab2(output)\n","    prediction = self.embedding2vocab3(output)\n","    # prediction = [batch size, vocab size]\n","    return prediction, hidden\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"faboaaSJAcpE","colab_type":"text"},"source":["## Attention\n","- 當輸入過長，或是單獨靠 “content vector” 無法取得整個輸入的意思時，用 Attention Mechanism 來提供 **Decoder** 更多的資訊\n","- 主要是根據現在 **Decoder hidden state** ，去計算在 **Encoder outputs** 中，那些與其有較高的關係，根據關系的數值來決定該傳給 **Decoder** 那些額外資訊 \n","- 常見 Attention 的實作是用 Neural Network / Dot Product 來算 **Decoder hidden state** 和 **Encoder outputs** 之間的關係，再對所有算出來的數值做 **softmax** ，最後根據過完 **softmax** 的值對 **Encoder outputs** 做 **weight sum**\n","\n","- TODO:\n","實作 Attention Mechanism"]},{"cell_type":"code","metadata":{"id":"imGefKRIAfBW","colab_type":"code","colab":{}},"source":["class Attention(nn.Module):\n","  def __init__(self, hid_dim):\n","    super(Attention, self).__init__()\n","    self.hid_dim = hid_dim\n","  \n","  def forward(self, encoder_outputs, decoder_hidden):\n","    # encoder_outputs = [batch size, sequence len, hid dim * directions]\n","    # decoder_hidden = [num_layers, batch size, hid dim]\n","    # 一般來說是取 Encoder 最後一層的 hidden state 來做 attention\n","    ########\n","    # TODO #\n","    ########\n","    attention=None\n","    \n","    return attention\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJjxd56yySun","colab_type":"text"},"source":["## Seq2Seq\n","- 由 **Encoder** 和 **Decoder** 組成\n","- 接收輸入並傳給 **Encoder** \n","- 將 **Encoder** 的輸出傳給 **Decoder**\n","- 不斷地將 **Decoder** 的輸出傳回 **Decoder** ，進行解碼  \n","- 當解碼完成後，將 **Decoder** 的輸出傳回 "]},{"cell_type":"code","metadata":{"id":"jjko57senVKG","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","  def __init__(self, encoder, decoder, device):\n","    super().__init__()\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.device = device\n","    assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","            \n","  def forward(self, input, target, teacher_forcing_ratio):\n","    # input  = [batch size, input len]\n","    # target = [batch size, target len]\n","    # teacher_forcing_ratio 是有多少機率使用正確答案來訓練\n","    batch_size = target.shape[0]\n","    target_len = target.shape[1]\n","    vocab_size = self.decoder.vocab_size\n","\n","    # 準備一個儲存空間來儲存輸出\n","    outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n","    # 將輸入放入 Encoder\n","    encoder_outputs, hidden = self.encoder(input)\n","    # Encoder 最後的隱藏層(hidden state) 用來初始化 Decoder\n","    # encoder_outputs 主要是使用在 Attention\n","    # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n","    # hidden =  [num_layers * directions, batch size  , hid dim]  --> [num_layers, directions, batch size  , hid dim]\n","    hidden = hidden.view(self.encoder.n_layers, 2, batch_size, -1)\n","    hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2)\n","    # 取的 <BOS> token\n","    input = target[:, 0]\n","    preds = []\n","    for t in range(1, target_len):\n","      output, hidden = self.decoder(input, hidden, encoder_outputs)\n","      outputs[:, t] = output\n","      # 決定是否用正確答案來做訓練\n","      teacher_force = random.random() <= teacher_forcing_ratio\n","      # 取出機率最大的單詞\n","      top1 = output.argmax(1)\n","      # 如果是 teacher force 則用正解訓練，反之用自己預測的單詞做預測\n","      input = target[:, t] if teacher_force and t < target_len else top1\n","      preds.append(top1.unsqueeze(1))\n","    preds = torch.cat(preds, 1)\n","    return outputs, preds\n","\n","  def inference(self, input, target):\n","    ########\n","    # TODO #\n","    ########\n","    # 在這裡實施 Beam Search\n","    # 此函式的 batch size = 1  \n","    # input  = [batch size, input len]\n","    # target = [batch size, target len]\n","    batch_size = input.shape[0]\n","    input_len = input.shape[1]        # 取得最大字數\n","    vocab_size = self.decoder.vocab_size\n","\n","    # 準備一個儲存空間來儲存輸出\n","    outputs = torch.zeros(batch_size, input_len, vocab_size).to(self.device)\n","    # 將輸入放入 Encoder\n","    encoder_outputs, hidden = self.encoder(input)\n","    # Encoder 最後的隱藏層(hidden state) 用來初始化 Decoder\n","    # encoder_outputs 主要是使用在 Attention\n","    # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n","    # hidden =  [num_layers * directions, batch size  , hid dim]  --> [num_layers, directions, batch size  , hid dim]\n","    hidden = hidden.view(self.encoder.n_layers, 2, batch_size, -1)\n","    hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2)\n","    # 取的 <BOS> token\n","    input = target[:, 0]\n","    preds = []\n","    for t in range(1, input_len):\n","      output, hidden = self.decoder(input, hidden, encoder_outputs)\n","      # 將預測結果存起來\n","      outputs[:, t] = output\n","      # 取出機率最大的單詞\n","      top1 = output.argmax(1)\n","      input = top1\n","      preds.append(top1.unsqueeze(1))\n","    preds = torch.cat(preds, 1)\n","    return outputs, preds\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eCOIUTOT59aL","colab_type":"text"},"source":["# utils\n","- 基本操作:\n","  - 儲存模型\n","  - 載入模型\n","  - 建構模型\n","  - 將一連串的數字還原回句子\n","  - 計算 BLEU score\n","  - 迭代 dataloader\n","  "]},{"cell_type":"markdown","metadata":{"id":"vMBoCSH5MBLN","colab_type":"text"},"source":["## 儲存模型"]},{"cell_type":"code","metadata":{"id":"uCZuQrWiMGmH","colab_type":"code","colab":{}},"source":["def save_model(model, optimizer, store_model_path, step):\n","  torch.save(model.state_dict(), f'{store_model_path}/model_{step}.ckpt')\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nde98xvAMxAd","colab_type":"text"},"source":["## 載入模型"]},{"cell_type":"code","metadata":{"id":"FGzZ2Yp2MxK-","colab_type":"code","colab":{}},"source":["def load_model(model, load_model_path):\n","  print(f'Load model from {load_model_path}')\n","  model.load_state_dict(torch.load(f'{load_model_path}.ckpt'))\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eoz6awEcOIAz","colab_type":"text"},"source":["## 建構模型"]},{"cell_type":"code","metadata":{"id":"TvWqv_JlOOix","colab_type":"code","colab":{}},"source":["def build_model(config, vocab_size):\n","  # 建構模型\n","  encoder = Encoder(vocab_size, config.emb_dim, config.hid_dim, config.n_layers, config.dropout)\n","  decoder = Decoder(vocab_size, config.emb_dim, config.hid_dim, config.n_layers, config.dropout, config.attention)\n","  model = Seq2Seq(encoder, decoder, device)\n","  print(model)\n","  # 建構 optimizer\n","  optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n","  print(optimizer)\n","  if config.load_model:\n","    model = load_model(model, config.load_model_path)\n","  model = model.to(device)\n","\n","  return model, optimizer\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qEu4V_axXCF9","colab_type":"text"},"source":["## 數字轉句子"]},{"cell_type":"code","metadata":{"id":"ekAoI7L5mlHq","colab_type":"code","colab":{}},"source":["def tokens2sentence(outputs, int2word):\n","  sentences = []\n","  for tokens in outputs:\n","    sentence = []\n","    for token in tokens:\n","      word = int2word[str(int(token))]\n","      if word == '<EOS>':\n","        break\n","      sentence.append(word)\n","    sentences.append(sentence)\n","  \n","  return sentences\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kwpb4LDFWplj","colab_type":"text"},"source":["## 計算 BLEU score"]},{"cell_type":"code","metadata":{"id":"WBRNZDsMo0hF","colab_type":"code","colab":{}},"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","\n","def computebleu(sentences, targets):\n","  score = 0 \n","  assert (len(sentences) == len(targets))\n","\n","  def cut_token(sentence):\n","    tmp = []\n","    for token in sentence:\n","      if token == '<UNK>' or token.isdigit() or len(bytes(token[0], encoding='utf-8')) == 1:\n","        tmp.append(token)\n","      else:\n","        tmp += [word for word in token]\n","    return tmp \n","\n","  for sentence, target in zip(sentences, targets):\n","    sentence = cut_token(sentence)\n","    target = cut_token(target)\n","    score += sentence_bleu([target], sentence, weights=(1, 0, 0, 0))                                                                                          \n","  \n","  return score\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-vijuXbMeJrn","colab_type":"text"},"source":["##迭代 dataloader"]},{"cell_type":"code","metadata":{"id":"iIZ44EdfeJ3i","colab_type":"code","colab":{}},"source":["def infinite_iter(data_loader):\n","  it = iter(data_loader)\n","  while True:\n","    try:\n","      ret = next(it)\n","      yield ret\n","    except StopIteration:\n","      it = iter(data_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aIfx7oj5fAjP","colab_type":"text"},"source":["## schedule_sampling"]},{"cell_type":"code","metadata":{"id":"AHuxM8m-fArz","colab_type":"code","colab":{}},"source":["########\n","# TODO #\n","########\n","\n","# 請在這裡直接 return 0 來取消 Teacher Forcing\n","# 請在這裡實作 schedule_sampling 的策略\n","\n","def schedule_sampling(step,summary_steps):\n","    return 1-0.8*step/summary_steps"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bBHAhX5e5xm4","colab_type":"text"},"source":["# 訓練步驟"]},{"cell_type":"markdown","metadata":{"id":"_q9Co3vuGWfu","colab_type":"text"},"source":["## 訓練\n","- 訓練階段"]},{"cell_type":"code","metadata":{"id":"TBnE9GbiO8Ob","colab_type":"code","colab":{}},"source":["def train(model, optimizer, train_iter, loss_function, total_steps, summary_steps, train_dataset):\n","  model.train()\n","  model.zero_grad()\n","  losses = []\n","  loss_sum = 0.0\n","  for step in range(summary_steps):\n","    sources, targets = next(train_iter)\n","    sources, targets = sources.to(device), targets.to(device)\n","    outputs, preds = model(sources, targets, schedule_sampling(step,summary_steps))\n","    # targets 的第一個 token 是 <BOS> 所以忽略\n","    outputs = outputs[:, 1:].reshape(-1, outputs.size(2))\n","    targets = targets[:, 1:].reshape(-1)\n","    loss = loss_function(outputs, targets)\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","    optimizer.step()\n","\n","    loss_sum += loss.item()\n","    if (step + 1) % 5 == 0:\n","      loss_sum = loss_sum / 5\n","      print (\"\\r\", \"train [{}] loss: {:.3f}, Perplexity: {:.3f}      \".format(total_steps + step + 1, loss_sum, np.exp(loss_sum)), end=\" \")\n","      losses.append(loss_sum)\n","      loss_sum = 0.0\n","\n","  return model, optimizer, losses\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6cuHVXxAfHrA","colab_type":"text"},"source":["## 檢驗/測試\n","- 防止訓練發生overfitting"]},{"cell_type":"code","metadata":{"id":"ZBp-n3FrfOCe","colab_type":"code","colab":{}},"source":["def test(model, dataloader, loss_function):\n","  model.eval()\n","  loss_sum, bleu_score= 0.0, 0.0\n","  n = 0\n","  result = []\n","  for sources, targets in dataloader:\n","    sources, targets = sources.to(device), targets.to(device)\n","    batch_size = sources.size(0)\n","    outputs, preds = model.inference(sources, targets)\n","    # targets 的第一個 token 是 <BOS> 所以忽略\n","    outputs = outputs[:, 1:].reshape(-1, outputs.size(2))\n","    targets = targets[:, 1:].reshape(-1)\n","\n","    loss = loss_function(outputs, targets)\n","    loss_sum += loss.item()\n","\n","    # 將預測結果轉為文字\n","    targets = targets.view(sources.size(0), -1)\n","    preds = tokens2sentence(preds, dataloader.dataset.int2word)\n","    sources = tokens2sentence(sources, dataloader.dataset.int2word)\n","    targets = tokens2sentence(targets, dataloader.dataset.int2word)\n","    for source, pred, target in zip(sources, preds, targets):\n","      result.append((pred, target))\n","    # 計算 Bleu Score\n","    bleu_score += computebleu(preds, targets)\n","\n","    n += batch_size\n","\n","  return loss_sum / len(dataloader), bleu_score / n, result\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dFEYmPAlx_SX","colab_type":"text"},"source":["## 訓練流程\n","- 先訓練，再檢驗"]},{"cell_type":"code","metadata":{"id":"cJ54vDP2yC2S","colab_type":"code","colab":{}},"source":["def train_process(config):\n","  # 準備訓練資料\n","  train_dataset = EN2CNDataset(config.data_path, config.max_output_len, 'rhythm_pattern_list_all.data')\n","  train_loader = data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n","  train_iter = infinite_iter(train_loader)\n","  # 準備檢驗資料\n","  val_dataset = EN2CNDataset(config.data_path, config.max_output_len, 'rhythm_pattern_list_all.data')\n","  val_loader = data.DataLoader(val_dataset, batch_size=1)\n","  # 建構模型\n","  model, optimizer = build_model(config, train_dataset.vocab_size)\n","  loss_function = nn.CrossEntropyLoss(ignore_index=0)\n","\n","  train_losses, val_losses, bleu_scores = [], [], []\n","  total_steps = 0\n","  while (total_steps < config.num_steps):\n","    # 訓練模型\n","    model, optimizer, loss = train(model, optimizer, train_iter, loss_function, total_steps, config.summary_steps, train_dataset)\n","    train_losses += loss\n","    # 檢驗模型\n","    val_loss, bleu_score, result = test(model, val_loader, loss_function)\n","    val_losses.append(val_loss)\n","    bleu_scores.append(bleu_score)\n","\n","    total_steps += config.summary_steps\n","    print (\"\\r\", \"val [{}] loss: {:.3f}, Perplexity: {:.3f}, blue score: {:.3f}       \".format(total_steps, val_loss, np.exp(val_loss), bleu_score))\n","    \n","    # 儲存模型和結果\n","    if total_steps % config.store_steps == 0 or total_steps >= config.num_steps:\n","      save_model(model, optimizer, config.store_model_path, total_steps)\n","      with open(f'{config.store_model_path}/output_{total_steps}.txt', 'w') as f:\n","        for line in result:\n","          print (line, file=f)\n","    \n","  return train_losses, val_losses, bleu_scores\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QZvo0u9SofwW","colab_type":"text"},"source":["## 測試流程"]},{"cell_type":"code","metadata":{"id":"tvpiHCM-ogNh","colab_type":"code","colab":{}},"source":["def test_process(config):\n","  # 準備測試資料\n","  test_dataset = EN2CNDataset(config.data_path, config.max_output_len, 'rhythm_pattern_list_all.data')\n","  test_loader = data.DataLoader(test_dataset, batch_size=1)\n","  # 建構模型\n","  model, optimizer = build_model(config, test_dataset.vocab_size)\n","  print (\"Finish build model\")\n","  loss_function = nn.CrossEntropyLoss(ignore_index=0)\n","  model.eval()\n","  # 測試模型\n","  test_loss, bleu_score, result = test(model, test_loader, loss_function)\n","  # 儲存結果\n","  with open(f'{config.store_model_path}/test_output.txt', 'w') as f:\n","    for line in result:\n","      print (line, file=f)\n","\n","  return test_loss, bleu_score, result\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7PbfgB3n9eoT","colab_type":"text"},"source":["# Config\n","- 實驗的參數設定表"]},{"cell_type":"code","metadata":{"id":"3kWSZ4w39gzj","colab_type":"code","colab":{}},"source":["class configurations(object):\n","  def __init__(self):\n","    self.batch_size = 1\n","    self.emb_dim = 256\n","    self.hid_dim = 512\n","    self.n_layers = 3\n","    self.dropout = 0.5\n","    self.learning_rate = 0.00005\n","    self.max_output_len = 50              # 最後輸出句子的最大長度\n","    self.num_steps = 300                # 總訓練次數\n","    self.store_steps = 2000                # 訓練多少次後須儲存模型\n","    self.summary_steps = 300              # 訓練多少次後須檢驗是否有overfitting\n","    self.load_model = True               # 是否需載入模型\n","    self.store_model_path = \"/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline\"      # 儲存模型的位置\n","    self.load_model_path = \"/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline/model_\"+str(12000)           # self.num_steps載入模型的位置 e.g. \"./ckpt/model_{step}\" \n","    self.data_path = \"/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/data_folder/\"          # 資料存放的位置\n","    self.attention = False                # 是否使用 Attention Mechanism\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"axqi9Qsb6mxV","colab_type":"text"},"source":["# 输出并转化为MIDI音乐"]},{"cell_type":"code","metadata":{"id":"hUU63nvKOTsz","colab_type":"code","colab":{}},"source":["import music21\n","from music21 import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZyzB0zxmkfAF","colab_type":"code","colab":{}},"source":["DURATION_EPS_FOR_RECONSTR = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhAanTmBLN8B","colab_type":"code","colab":{}},"source":["#TODO: translate string of rhythm patterns into music21 objects\n","#lib: from music21 import *\n","#input: strings like 'N0.500,N0.500,N0.500,N0.500,N0.500,N0.500,N0.500,N0.500|4/4'\n","#output: list of notes\n","def translate_pattern_string_into_obj(rhythm_string):\n","    global DURATION_EPS_FOR_RECONSTR\n","    symbol_list=[]\n","    if rhythm_string[0] == '|':\n","        symbol_list.append(meter.TimeSignature(rhythm_string[1:]))\n","    elif rhythm_string[0] == '<':\n","        pass\n","    else:\n","        meter_index=rhythm_string.find('|')\n","        meter_str=rhythm_string[meter_index+1:]\n","\n","        divide_index=meter_str.find('/')\n","        element_duration=round(4/float(meter_str[divide_index+1:]),3)\n","        count_per_measure=int(meter_str[0:divide_index])\n","        string_duration=count_per_measure*element_duration\n","        #print('string_duration=',string_duration)\n","\n","        tmp_str=rhythm_string.replace('|'+meter_str,'')\n","        obj_list=tmp_str.split(',')\n","        duration_buff=0\n","\n","        for obj_str in obj_list:\n","            obj_type = obj_str[0]\n","            this_duration = float(obj_str[1:])\n","            duration_buff+=this_duration\n","            if obj_type=='H' or obj_type=='N':\n","                this_obj = note.Note('C5')\n","            elif obj_type=='R':\n","                this_obj = note.Rest('')\n","            this_obj.duration = duration.Duration(this_duration)\n","            symbol_list.append(this_obj)\n","\n","        if abs(duration_buff-string_duration)>DURATION_EPS_FOR_RECONSTR:\n","            print('This rhythm string is '+rhythm_string)\n","            print('string_duration=',string_duration)\n","            print('duration_buff=',duration_buff)\n","            assert abs(duration_buff-string_duration)<=DURATION_EPS_FOR_RECONSTR, 'Note duration not compatable with meter!'\n","    return symbol_list\n","\n","def translate_rhythm_string_list_into_stream(string_list):\n","    symbol_list=[]\n","    for string in string_list:\n","        symbol_list = symbol_list+translate_pattern_string_into_obj(string)\n","    symbol_stream_tmp=music21.stream.Stream()\n","    for obj in symbol_list:\n","        symbol_stream_tmp.append(obj)\n","    return symbol_stream_tmp\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zccn2XRIKBn2","colab_type":"code","colab":{}},"source":["def result_tuplelist_to_midi(result_list_of_tuples,midi_results_path,max_file_num=None):\n","    if not max_file_num:\n","        max_file_num = len(result_list_of_tuples)\n","    for index,piece in enumerate(result_list_of_tuples):\n","        pred=piece[0]\n","        target=piece[1]\n","        print('Writing midi file number',index)\n","        test_stream_result=translate_rhythm_string_list_into_stream(pred)\n","        test_stream_target=translate_rhythm_string_list_into_stream(target)\n","        test_stream_result.write('midi', fp=midi_results_path+'/the_test_stream_result'+str(index)+'.mid')\n","        test_stream_target.write('midi', fp=midi_results_path+'/the_test_stream_target'+str(index)+'.mid')\n","        if index>max_file_num:\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w464f4KOLUh6","colab_type":"text"},"source":["#Main Function\n","- 讀入參數\n","- 進行訓練或是推論"]},{"cell_type":"markdown","metadata":{"id":"qlwNx0z6vu_S","colab_type":"text"},"source":["## train"]},{"cell_type":"code","metadata":{"id":"6kLJFKUB8c6M","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  config = configurations()\n","  print ('config:\\n', vars(config))\n","  train_losses, val_losses, bleu_scores = train_process(config)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EjDNDiwZvyCn","colab_type":"text"},"source":["## test"]},{"cell_type":"code","metadata":{"id":"N00ZAkL7ieGP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":839},"executionInfo":{"status":"ok","timestamp":1591003545443,"user_tz":-480,"elapsed":33293,"user":{"displayName":"Lu Tongyu","photoUrl":"","userId":"13618470284889852279"}},"outputId":"8ecdfd39-4ce2-4868-b5c8-fb663165afae"},"source":["# 在執行 Test 之前，請先行至 config 設定所要載入的模型位置\n","if __name__ == '__main__':\n","  config = configurations()\n","  print ('config:\\n', vars(config))\n","  test_loss, bleu_score, result_list_of_tuples = test_process(config)\n","  print (f'test loss: {test_loss}, bleu_score: {bleu_score}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["config:\n"," {'batch_size': 1, 'emb_dim': 256, 'hid_dim': 512, 'n_layers': 3, 'dropout': 0.5, 'learning_rate': 5e-05, 'max_output_len': 50, 'num_steps': 300, 'store_steps': 2000, 'summary_steps': 300, 'load_model': True, 'store_model_path': '/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline', 'load_model_path': '/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline/model_12000', 'data_path': '/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/data_folder/', 'attention': False}\n","rhythm_pattern_list_all.data dataset size: 1032\n","Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(467, 256)\n","    (rnn): GRU(256, 512, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(467, 256)\n","    (attention): Attention()\n","    (rnn): GRU(256, 1024, num_layers=3, batch_first=True, dropout=0.5)\n","    (embedding2vocab1): Linear(in_features=1024, out_features=2048, bias=True)\n","    (embedding2vocab2): Linear(in_features=2048, out_features=4096, bias=True)\n","    (embedding2vocab3): Linear(in_features=4096, out_features=467, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 5e-05\n","    weight_decay: 0\n",")\n","Load model from /content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline/model_12000\n","Finish build model\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["test loss: 1.6380730721045487, bleu_score: 0.6236905419846795\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sNS0aR0zMIIx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1591005462276,"user_tz":-480,"elapsed":56322,"user":{"displayName":"Lu Tongyu","photoUrl":"","userId":"13618470284889852279"}},"outputId":"ccc9d289-6f6c-41aa-90dc-ba981bb5f8d9"},"source":["midi_results_path = '/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline/midi_rhythm_results'\n","result_tuplelist_to_midi(result_list_of_tuples,midi_results_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing midi file number 0\n","Writing midi file number 1\n","Writing midi file number 2\n","Writing midi file number 3\n","Writing midi file number 4\n","Writing midi file number 5\n","Writing midi file number 6\n","Writing midi file number 7\n","Writing midi file number 8\n","Writing midi file number 9\n","Writing midi file number 10\n","Writing midi file number 11\n","Writing midi file number 12\n","Writing midi file number 13\n","Writing midi file number 14\n","Writing midi file number 15\n","Writing midi file number 16\n","Writing midi file number 17\n","Writing midi file number 18\n","Writing midi file number 19\n","Writing midi file number 20\n","Writing midi file number 21\n","Writing midi file number 22\n","Writing midi file number 23\n","Writing midi file number 24\n","Writing midi file number 25\n","Writing midi file number 26\n","Writing midi file number 27\n","Writing midi file number 28\n","Writing midi file number 29\n","Writing midi file number 30\n","Writing midi file number 31\n","Writing midi file number 32\n","Writing midi file number 33\n","Writing midi file number 34\n","Writing midi file number 35\n","Writing midi file number 36\n","Writing midi file number 37\n","Writing midi file number 38\n","Writing midi file number 39\n","Writing midi file number 40\n","Writing midi file number 41\n","Writing midi file number 42\n","Writing midi file number 43\n","Writing midi file number 44\n","Writing midi file number 45\n","Writing midi file number 46\n","Writing midi file number 47\n","Writing midi file number 48\n","Writing midi file number 49\n","Writing midi file number 50\n","Writing midi file number 51\n","Writing midi file number 52\n","Writing midi file number 53\n","Writing midi file number 54\n","Writing midi file number 55\n","Writing midi file number 56\n","Writing midi file number 57\n","Writing midi file number 58\n","Writing midi file number 59\n","Writing midi file number 60\n","Writing midi file number 61\n","Writing midi file number 62\n","Writing midi file number 63\n","Writing midi file number 64\n","Writing midi file number 65\n","Writing midi file number 66\n","Writing midi file number 67\n","Writing midi file number 68\n","Writing midi file number 69\n","Writing midi file number 70\n","Writing midi file number 71\n","Writing midi file number 72\n","Writing midi file number 73\n","Writing midi file number 74\n","Writing midi file number 75\n","Writing midi file number 76\n","Writing midi file number 77\n","Writing midi file number 78\n","Writing midi file number 79\n","Writing midi file number 80\n","Writing midi file number 81\n","Writing midi file number 82\n","Writing midi file number 83\n","Writing midi file number 84\n","Writing midi file number 85\n","Writing midi file number 86\n","Writing midi file number 87\n","Writing midi file number 88\n","Writing midi file number 89\n","Writing midi file number 90\n","Writing midi file number 91\n","Writing midi file number 92\n","Writing midi file number 93\n","Writing midi file number 94\n","Writing midi file number 95\n","Writing midi file number 96\n","Writing midi file number 97\n","Writing midi file number 98\n","Writing midi file number 99\n","Writing midi file number 100\n","Writing midi file number 101\n","Writing midi file number 102\n","Writing midi file number 103\n","Writing midi file number 104\n","Writing midi file number 105\n","Writing midi file number 106\n","Writing midi file number 107\n","Writing midi file number 108\n","Writing midi file number 109\n","Writing midi file number 110\n","Writing midi file number 111\n","Writing midi file number 112\n","Writing midi file number 113\n","Writing midi file number 114\n","Writing midi file number 115\n","Writing midi file number 116\n","Writing midi file number 117\n","Writing midi file number 118\n","Writing midi file number 119\n","Writing midi file number 120\n","Writing midi file number 121\n","Writing midi file number 122\n","Writing midi file number 123\n","Writing midi file number 124\n","Writing midi file number 125\n","Writing midi file number 126\n","Writing midi file number 127\n","Writing midi file number 128\n","Writing midi file number 129\n","Writing midi file number 130\n","Writing midi file number 131\n","Writing midi file number 132\n","Writing midi file number 133\n","Writing midi file number 134\n","Writing midi file number 135\n","Writing midi file number 136\n","Writing midi file number 137\n","Writing midi file number 138\n","Writing midi file number 139\n","Writing midi file number 140\n","Writing midi file number 141\n","Writing midi file number 142\n","Writing midi file number 143\n","Writing midi file number 144\n","Writing midi file number 145\n","Writing midi file number 146\n","Writing midi file number 147\n","Writing midi file number 148\n","Writing midi file number 149\n","Writing midi file number 150\n","Writing midi file number 151\n","Writing midi file number 152\n","Writing midi file number 153\n","Writing midi file number 154\n","Writing midi file number 155\n","Writing midi file number 156\n","Writing midi file number 157\n","Writing midi file number 158\n","Writing midi file number 159\n","Writing midi file number 160\n","Writing midi file number 161\n","Writing midi file number 162\n","Writing midi file number 163\n","Writing midi file number 164\n","Writing midi file number 165\n","Writing midi file number 166\n","Writing midi file number 167\n","Writing midi file number 168\n","Writing midi file number 169\n","Writing midi file number 170\n","Writing midi file number 171\n","Writing midi file number 172\n","Writing midi file number 173\n","Writing midi file number 174\n","Writing midi file number 175\n","Writing midi file number 176\n","Writing midi file number 177\n","Writing midi file number 178\n","Writing midi file number 179\n","Writing midi file number 180\n","Writing midi file number 181\n","Writing midi file number 182\n","Writing midi file number 183\n","Writing midi file number 184\n","Writing midi file number 185\n","Writing midi file number 186\n","Writing midi file number 187\n","Writing midi file number 188\n","Writing midi file number 189\n","Writing midi file number 190\n","Writing midi file number 191\n","Writing midi file number 192\n","Writing midi file number 193\n","Writing midi file number 194\n","Writing midi file number 195\n","Writing midi file number 196\n","Writing midi file number 197\n","Writing midi file number 198\n","Writing midi file number 199\n","Writing midi file number 200\n","Writing midi file number 201\n","Writing midi file number 202\n","Writing midi file number 203\n","Writing midi file number 204\n","Writing midi file number 205\n","Writing midi file number 206\n","Writing midi file number 207\n","Writing midi file number 208\n","Writing midi file number 209\n","Writing midi file number 210\n","Writing midi file number 211\n","Writing midi file number 212\n","Writing midi file number 213\n","Writing midi file number 214\n","Writing midi file number 215\n","Writing midi file number 216\n","Writing midi file number 217\n","Writing midi file number 218\n","Writing midi file number 219\n","Writing midi file number 220\n","Writing midi file number 221\n","Writing midi file number 222\n","Writing midi file number 223\n","Writing midi file number 224\n","Writing midi file number 225\n","Writing midi file number 226\n","Writing midi file number 227\n","Writing midi file number 228\n","Writing midi file number 229\n","Writing midi file number 230\n","Writing midi file number 231\n","Writing midi file number 232\n","Writing midi file number 233\n","Writing midi file number 234\n","Writing midi file number 235\n","Writing midi file number 236\n","Writing midi file number 237\n","Writing midi file number 238\n","Writing midi file number 239\n","Writing midi file number 240\n","Writing midi file number 241\n","Writing midi file number 242\n","Writing midi file number 243\n","Writing midi file number 244\n","Writing midi file number 245\n","Writing midi file number 246\n","Writing midi file number 247\n","Writing midi file number 248\n","Writing midi file number 249\n","Writing midi file number 250\n","Writing midi file number 251\n","Writing midi file number 252\n","Writing midi file number 253\n","Writing midi file number 254\n","Writing midi file number 255\n","Writing midi file number 256\n","Writing midi file number 257\n","Writing midi file number 258\n","Writing midi file number 259\n","Writing midi file number 260\n","Writing midi file number 261\n","Writing midi file number 262\n","Writing midi file number 263\n","Writing midi file number 264\n","Writing midi file number 265\n","Writing midi file number 266\n","Writing midi file number 267\n","Writing midi file number 268\n","Writing midi file number 269\n","Writing midi file number 270\n","Writing midi file number 271\n","Writing midi file number 272\n","Writing midi file number 273\n","Writing midi file number 274\n","Writing midi file number 275\n","Writing midi file number 276\n","Writing midi file number 277\n","Writing midi file number 278\n","Writing midi file number 279\n","Writing midi file number 280\n","Writing midi file number 281\n","Writing midi file number 282\n","Writing midi file number 283\n","Writing midi file number 284\n","Writing midi file number 285\n","Writing midi file number 286\n","Writing midi file number 287\n","Writing midi file number 288\n","Writing midi file number 289\n","Writing midi file number 290\n","Writing midi file number 291\n","Writing midi file number 292\n","Writing midi file number 293\n","Writing midi file number 294\n","Writing midi file number 295\n","Writing midi file number 296\n","Writing midi file number 297\n","Writing midi file number 298\n","Writing midi file number 299\n","Writing midi file number 300\n","Writing midi file number 301\n","Writing midi file number 302\n","Writing midi file number 303\n","Writing midi file number 304\n","Writing midi file number 305\n","Writing midi file number 306\n","Writing midi file number 307\n","Writing midi file number 308\n","Writing midi file number 309\n","Writing midi file number 310\n","Writing midi file number 311\n","Writing midi file number 312\n","Writing midi file number 313\n","Writing midi file number 314\n","This rhythm string is N3.000,N1.000,N1.000,N3.000,N1.000|6/4\n","string_duration= 6.0\n","duration_buff= 9.0\n"],"name":"stdout"},{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-16926102397c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmidi_results_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline/midi_rhythm_results'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult_tuplelist_to_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_list_of_tuples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmidi_results_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-62-c3e26c3c65c8>\u001b[0m in \u001b[0;36mresult_tuplelist_to_midi\u001b[0;34m(result_list_of_tuples, midi_results_path, max_file_num)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Writing midi file number'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtest_stream_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranslate_rhythm_string_list_into_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtest_stream_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranslate_rhythm_string_list_into_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtest_stream_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'midi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmidi_results_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/the_test_stream_result'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtest_stream_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'midi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmidi_results_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/the_test_stream_target'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-829603fadb42>\u001b[0m in \u001b[0;36mtranslate_rhythm_string_list_into_stream\u001b[0;34m(string_list)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0msymbol_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msymbol_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbol_list\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtranslate_pattern_string_into_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0msymbol_stream_tmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmusic21\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbol_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-829603fadb42>\u001b[0m in \u001b[0;36mtranslate_pattern_string_into_obj\u001b[0;34m(rhythm_string)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'string_duration='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstring_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'duration_buff='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mduration_buff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration_buff\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstring_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mDURATION_EPS_FOR_RECONSTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Note duration not compatable with meter!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msymbol_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Note duration not compatable with meter!"]}]},{"cell_type":"markdown","metadata":{"id":"JyhX44s2wS1I","colab_type":"text"},"source":["# 圖形化訓練過程"]},{"cell_type":"markdown","metadata":{"id":"nNnx0AcDxiJz","colab_type":"text"},"source":["## 以圖表呈現 訓練 的 loss 變化趨勢"]},{"cell_type":"code","metadata":{"id":"EahLuZ2X8zdF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"error","timestamp":1590821623201,"user_tz":-480,"elapsed":143774,"user":{"displayName":"严律成","photoUrl":"","userId":"17774493152554177867"}},"outputId":"8d677322-9077-448b-a8bc-4bd57f4ac542"},"source":["import matplotlib.pyplot as plt\n","plt.figure()\n","plt.plot(train_losses)\n","plt.xlabel('次數')\n","plt.ylabel('loss')\n","plt.title('train loss')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-e3e7c173b830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'次數'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"WbEi0MMGxl-v","colab_type":"text"},"source":["## 以圖表呈現 檢驗 的 loss 變化趨勢"]},{"cell_type":"code","metadata":{"id":"tJEqy0aBxA3E","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.figure()\n","plt.plot(val_losses)\n","plt.xlabel('次數')\n","plt.ylabel('loss')\n","plt.title('validation loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C5SJkPbgxp0m","colab_type":"text"},"source":["## BLEU score"]},{"cell_type":"code","metadata":{"id":"jhQ3Z7NPxBB8","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.figure()\n","plt.plot(bleu_scores)\n","plt.xlabel('次數')\n","plt.ylabel('BLEU score')\n","plt.title('BLEU score')\n","plt.show()"],"execution_count":null,"outputs":[]}]}