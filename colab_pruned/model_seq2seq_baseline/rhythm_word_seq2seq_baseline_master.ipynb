{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rhythm_word_seq2seq_baseline_master.ipynb","provenance":[{"file_id":"1Pm7NKYjKQzXNKxJfDrVDetx_ZC7yXlOX","timestamp":1592584839422}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1Pm7NKYjKQzXNKxJfDrVDetx_ZC7yXlOX","authorship_tag":"ABX9TyPbfDhvCFpm5uwtT9NI5gHK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yizCV24kz9qQ","colab_type":"text"},"source":["#Baseline rhythm generation model\n","- modified based on Hungyi-Lee's HW8 structure: https://colab.research.google.com/drive/11iwJbQv9iScRo6kGP7YfyHaaorlHhzMT"]},{"cell_type":"code","metadata":{"id":"8ZtzTW0ipIxR","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torch.utils.data.sampler as sampler\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","import numpy as np\n","import sys\n","import os\n","import random\n","import json\n","import re\n","import pickle\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqcT8J2Jwcgk","colab_type":"code","colab":{}},"source":["class LabelTransform(object):\n","    def __init__(self, size, pad):\n","        self.size = size\n","        self.pad = pad\n","\n","    def __call__(self, label):\n","        label = np.pad(label, (0, (self.size - label.shape[0])), mode='constant', constant_values=self.pad)\n","        return label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mg4hW-oBwckD","colab_type":"code","colab":{}},"source":["class RhythmDataset(data.Dataset):\n","    def __init__(self, root, max_output_len, set_name):\n","        self.root = root\n","        self.max_output_len = max_output_len\n","        self.word2int, self.int2word = self.get_dictionary()\n","\n","        # 載入資料\n","        self.data = []\n","        with open(os.path.join(self.root, f'{set_name}'), \"rb\") as f:\n","            self.data=pickle.load(f)\n","            print (f'{set_name} dataset size: {len(self.data)}')\n","\n","        self.vocab_size = len(self.word2int)\n","\n","        self.transform = LabelTransform(max_output_len, self.word2int['<PAD>'])\n","\n","    def get_dictionary(self):\n","        # 載入字典\n","        with open(os.path.join(self.root+'/rhythm_dict', f'vocab_word2int.json'), \"r\") as f:\n","            word2int = json.load(f)\n","        with open(os.path.join(self.root+'/rhythm_dict', f'vocab_int2word.json'), \"r\") as f:\n","            int2word = json.load(f)\n","        return word2int, int2word\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, Index, pad=False):\n","        global device\n","        sentence = self.data[Index]\n","        sentence_idx = []\n","        for word in sentence:\n","            if (word in self.word2int.keys()):\n","                sentence_idx.append(self.word2int[word])\n","            else:#如果遇到不会的单词就赋给不知道\n","                sentence_idx.append(self.word2int[\"<UNK>\"])\n","        if pad:\n","            sentence_idx = np.asarray(sentence_idx)\n","            sentence_idx = self.transform(sentence_idx)\n","\n","        sentence_idx = torch.LongTensor(sentence_idx).to(device)\n","        target = sentence_idx.clone()\n","        return sentence_idx, target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqmiDklbwvQR","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input):\n","        # input: [batch_size, sequence_len]\n","        embedding = self.embedding(input)\n","        outputs, hidden = self.rnn(self.dropout(embedding))\n","        # outputs: [batch_size, sequence_len, hid_dim * directions]\n","        # hidden:  [num_layers * directions, batch_size  , hid_dim]\n","        return outputs, hidden\n","\n","    def get_embedding(self, input):\n","        # input: [batch_size, sequence_len]\n","        embedding = self.embedding(input)\n","        return embedding"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tRBlSUgw7-t","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.hid_dim = hid_dim * 2\n","        self.n_layers = n_layers\n","        self.embedding = nn.Embedding(vocab_size, config.emb_dim)\n","        self.input_dim = emb_dim\n","        self.rnn = nn.GRU(self.input_dim, self.hid_dim, self.n_layers, dropout = dropout, batch_first=True)\n","        self.embedding2vocab1 = nn.Linear(self.hid_dim, self.hid_dim * 2)\n","        self.embedding2vocab2 = nn.Linear(self.hid_dim * 2, self.hid_dim * 4)\n","        self.embedding2vocab3 = nn.Linear(self.hid_dim * 4, self.vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        # input: [batch_size, 1]\n","        # hidden: [batch_size, n_layers * directions, hid_dim]\n","        # Decoder's directions=1\n","        input = input.unsqueeze(1)\n","        embedded = self.dropout(self.embedding(input))\n","        # embedded: [batch_size, 1, emb_dim]\n","        output, hidden = self.rnn(embedded, hidden)\n","        # output: [batch_size, 1, hid_dim]\n","        # hidden: [num_layers, batch_size, hid_dim]\n","\n","        output = self.embedding2vocab1(output.squeeze(1))\n","        output = self.embedding2vocab2(output)\n","        prediction = self.embedding2vocab3(output)\n","        # prediction: [batch_size, vocab_size]\n","        return prediction, hidden\n","    \n","    def get_embedding(self, input):\n","        # input: [batch_size, sequence_len]\n","        embedding = self.embedding(input)\n","        return embedding"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RC4ZcOq2xuBz","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        assert encoder.n_layers == decoder.n_layers, \\\n","                \"Encoder and decoder must have equal number of layers!\"\n","            \n","    def forward(self, input, target, teacher_forcing_ratio):\n","        # input: [batch_size, input_len]\n","        # target: [batch_size, target_len]\n","        batch_size = target.shape[0]\n","        target_len = target.shape[1]\n","        vocab_size = self.decoder.vocab_size\n","\n","        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n","        encoder_outputs, hidden = self.encoder(input)\n","        # hidden =  [num_layers * directions, batch_size, hid_dim]  --> [num_layers, directions, batch_size, hid_dim]\n","        hidden = hidden.view(self.encoder.n_layers, 2, batch_size, -1)\n","        hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2)\n","        # <BOS> token\n","        input = target[:, 0]\n","        preds = []\n","        for t in range(1, target_len):\n","            output, hidden = self.decoder(input, hidden, encoder_outputs)\n","            outputs[:, t] = output\n","            teacher_force = random.random() <= teacher_forcing_ratio\n","            top1 = output.argmax(1)\n","            input = target[:, t] if teacher_force and t < target_len else top1\n","            preds.append(top1.unsqueeze(1))\n","        preds = torch.cat(preds, 1)\n","        #print(preds)\n","        return outputs, preds\n","\n","    def inference(self, input, target):\n","        # TODO: Beam Search\n","        batch_size = input.shape[0]\n","        input_len = input.shape[1]\n","        vocab_size = self.decoder.vocab_size\n","        #print('input_len=',input_len)\n","        outputs = torch.zeros(batch_size, input_len, vocab_size).to(self.device)\n","        encoder_outputs, hidden = self.encoder(input)\n","        hidden = hidden.view(self.encoder.n_layers, 2, batch_size, -1)\n","        hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2)\n","        input = target[:, 0]\n","        preds = []\n","        for t in range(1, input_len):\n","            output, hidden = self.decoder(input, hidden, encoder_outputs)\n","            outputs[:, t] = output\n","            top1 = output.argmax(1)\n","            input = top1\n","            preds.append(top1.unsqueeze(1))\n","        preds = torch.cat(preds, 1)\n","        #print(preds)\n","        return outputs, preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uo_SfO9iwvtG","colab_type":"code","colab":{}},"source":["def build_model(config, vocab_size):\n","    encoder = Encoder(vocab_size, config.emb_dim, config.hid_dim, config.n_layers, config.dropout)\n","    decoder = Decoder(vocab_size, config.emb_dim, config.hid_dim, config.n_layers, config.dropout)\n","    model = Seq2Seq(encoder, decoder, device)\n","    print(model)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n","    print(optimizer)\n","    if config.load_model:\n","        model = load_model(model, config.load_model_path)\n","    model = model.to(device)\n","    return model, optimizer\n","\n","def save_model(model, optimizer, store_model_path, step):\n","    torch.save(model.state_dict(), f'{store_model_path}/model_{step}.ckpt')\n","    return\n","\n","def load_model(model, load_model_path):\n","    print(f'Load model from {load_model_path}')\n","    model.load_state_dict(torch.load(f'{load_model_path}.ckpt'))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"axXTd1Jdwvvm","colab_type":"code","colab":{}},"source":["def tokens2sentence(outputs, int2word):\n","    sentences = []\n","    for tokens in outputs:\n","        sentence = []\n","        for token in tokens:\n","            word = int2word[str(int(token))]\n","            if word == '<EOS>':\n","                break\n","            sentence.append(word)\n","        sentences.append(sentence)\n","    \n","    return sentences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgINQTpLyvJR","colab_type":"code","colab":{}},"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","\n","def computebleu(sentences, targets):\n","    score = 0 \n","    if len(sentences) < len(targets):\n","        #print(sentences)\n","        #print(targets)\n","        to_add = len(targets)-len(sentences)\n","        for i in range(to_add):\n","            sentences.append('<PAD>')\n","    else:\n","        assert (len(sentences) == len(targets))\n","\n","\n","    def cut_token(sentence):\n","        tmp = []\n","        for token in sentence:\n","            if token == '<UNK>' or token.isdigit() or len(bytes(token[0], encoding='utf-8')) == 1:\n","                tmp.append(token)\n","            else:\n","                tmp += [word for word in token]\n","        return tmp \n","\n","    for sentence, target in zip(sentences, targets):\n","        sentence = cut_token(sentence)\n","        target = cut_token(target)\n","        score += sentence_bleu([target], sentence, weights=(1, 0, 0, 0))                                                                                          \n","    \n","    return score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2tBSGZOsy2Rw","colab_type":"code","colab":{}},"source":["def infinite_iter(data_loader):\n","    it = iter(data_loader)\n","    while True:\n","        try:\n","            ret = next(it)\n","            yield ret\n","        except StopIteration:\n","            it = iter(data_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltp5-iA1y_6u","colab_type":"code","colab":{}},"source":["def schedule_sampling(step,summary_steps):\n","    return 1-0.8*step/summary_steps"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4rar2KtzCZj","colab_type":"code","colab":{}},"source":["def train(model, optimizer, train_iter, loss_function, total_steps, summary_steps, train_dataset):\n","    model.train()\n","    model.zero_grad()\n","    losses = []\n","    loss_sum = 0.0\n","    for step in range(summary_steps):\n","        sources, targets = next(train_iter)\n","        sources, targets = sources.to(device), targets.to(device)\n","        outputs, preds = model(sources, targets, schedule_sampling(step,summary_steps))\n","\n","        outputs = outputs.reshape(-1, outputs.size(2))\n","        targets = targets.reshape(-1)\n","        loss = loss_function(outputs, targets)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","        optimizer.step()\n","\n","        loss_sum += loss.item()\n","        if (step + 1) % 5 == 0:\n","            loss_sum = loss_sum / 5\n","            print (\"\\r\", \"train [{}] loss: {:.3f}, Perplexity: {:.3f}      \".format(total_steps + step + 1, loss_sum, np.exp(loss_sum)), end=\" \")\n","            losses.append(loss_sum)\n","            loss_sum = 0.0\n","\n","    return model, optimizer, losses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7Z-Ic4XzJ4t","colab_type":"code","colab":{}},"source":["def test(model, dataloader, loss_function):\n","    model.eval()\n","    loss_sum, bleu_score= 0.0, 0.0\n","    n = 0\n","    result = []\n","    for sources, targets in dataloader:\n","        sources, targets = sources.to(device), targets.to(device)\n","        batch_size = sources.size(0)\n","        outputs, preds = model.inference(sources, targets)\n","        outputs = outputs.reshape(-1, outputs.size(2))\n","        targets = targets.reshape(-1)\n","\n","        loss = loss_function(outputs, targets)\n","        loss_sum += loss.item()\n","\n","        # result2text\n","        targets = targets.view(batch_size, -1)\n","        # print(preds.shape)\n","        # print(targets.shape)\n","        # assert 0\n","        preds = tokens2sentence(preds, dataloader.dataset.int2word)\n","        targets = tokens2sentence(targets, dataloader.dataset.int2word)\n","\n","        for pred, target in zip(preds, targets):\n","            result.append((pred, target))\n","        \n","        bleu_score += computebleu(preds, targets)\n","        n += batch_size\n","\n","    return loss_sum / len(dataloader), bleu_score / n, result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyeF1jjzzOuy","colab_type":"code","colab":{}},"source":["def train_process(config):\n","    train_dataset = RhythmDataset(config.data_path, config.max_output_len, 'rhythm_pattern_list_all.data')\n","    train_loader = data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n","    train_iter = infinite_iter(train_loader)\n","\n","    val_dataset = RhythmDataset(config.data_path, config.max_output_len, 'rhythm_pattern_list_all.data')\n","    val_loader = data.DataLoader(val_dataset, batch_size=1)\n","\n","    model, optimizer = build_model(config, train_dataset.vocab_size)\n","    loss_function = nn.CrossEntropyLoss(ignore_index=0)\n","\n","    train_losses, val_losses, bleu_scores = [], [], []\n","    total_steps = 0\n","    while (total_steps < config.num_steps):\n","        #train\n","        model, optimizer, loss = train(model, optimizer, train_iter, loss_function, total_steps, config.summary_steps, train_dataset)\n","        train_losses += loss\n","        #test\n","        val_loss, bleu_score, result = test(model, val_loader, loss_function)\n","        val_losses.append(val_loss)\n","        bleu_scores.append(bleu_score)\n","\n","        total_steps += config.summary_steps\n","        print (\"\\r\", \"val [{}] loss: {:.3f}, Perplexity: {:.3f}, blue score: {:.3f}       \".format(total_steps, val_loss, np.exp(val_loss), bleu_score))\n","        \n","        #save\n","        if total_steps % config.store_steps == 0 or total_steps >= config.num_steps:\n","            save_model(model, optimizer, config.store_model_path, total_steps)\n","        with open(f'{config.store_model_path}/output_{total_steps}.txt', 'w') as f:\n","            for line in result:\n","                print (line, file=f)\n","        \n","    return train_losses, val_losses, bleu_scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDjTVG7dzeQY","colab_type":"code","colab":{}},"source":["def test_process(config):\n","    test_dataset = RhythmDataset(config.data_path, config.max_output_len, 'rhythm_pattern_list_all.data')\n","    test_loader = data.DataLoader(test_dataset, batch_size=1)\n","    model, optimizer = build_model(config, test_dataset.vocab_size)\n","    print (\"Finish build model\")\n","    loss_function = nn.CrossEntropyLoss(ignore_index=0)\n","    model.eval()\n","    #test\n","    test_loss, bleu_score, result = test(model, test_loader, loss_function)\n","    #save\n","    with open(f'{config.store_model_path}/test_output.txt', 'w') as f:\n","        for line in result:\n","            print (line, file=f)\n","    return test_loss, bleu_score, result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mH5vUWb3zm42","colab_type":"code","colab":{}},"source":["class configurations(object):\n","    def __init__(self):\n","        self.batch_size = 1\n","        self.emb_dim = 256\n","        self.hid_dim = 512\n","        self.n_layers = 3\n","        self.dropout = 0.5\n","        self.learning_rate = 0.00005\n","        self.max_output_len = 100\n","        self.num_steps = 9000\n","        self.store_steps = 2000\n","        self.summary_steps = 300\n","        self.load_model = False\n","        self.store_model_path = \"/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline\"\n","        self.load_model_path = \"/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline/model_\"+str(12000)\n","        self.data_path = \"/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/data_folder/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLwQFOzHzeab","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":818},"executionInfo":{"status":"ok","timestamp":1592572665976,"user_tz":-480,"elapsed":850836,"user":{"displayName":"Lu Tongyu","photoUrl":"","userId":"13618470284889852279"}},"outputId":"9f229a5f-9a30-4c79-82ce-f21e01f4c598"},"source":["config = configurations()\n","print ('config:\\n', vars(config))\n","train_losses, val_losses, bleu_scores = train_process(config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["config:\n"," {'batch_size': 1, 'emb_dim': 256, 'hid_dim': 512, 'n_layers': 3, 'dropout': 0.5, 'learning_rate': 5e-05, 'max_output_len': 100, 'num_steps': 1500, 'store_steps': 2000, 'summary_steps': 300, 'load_model': False, 'store_model_path': '/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline', 'load_model_path': '/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/model_seq2seq_baseline/model_12000', 'data_path': '/content/drive/My Drive/Colab Notebooks/music_GAN_rhythm_seed/data_folder/'}\n","rhythm_pattern_list_all.data dataset size: 1019\n","rhythm_pattern_list_all.data dataset size: 1019\n","Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(448, 256)\n","    (rnn): GRU(256, 512, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(448, 256)\n","    (rnn): GRU(256, 1024, num_layers=3, batch_first=True, dropout=0.5)\n","    (embedding2vocab1): Linear(in_features=1024, out_features=2048, bias=True)\n","    (embedding2vocab2): Linear(in_features=2048, out_features=4096, bias=True)\n","    (embedding2vocab3): Linear(in_features=4096, out_features=448, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 5e-05\n","    weight_decay: 0\n",")\n"," train [300] loss: 3.138, Perplexity: 23.057       "],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":[" val [300] loss: 3.666, Perplexity: 39.088, blue score: 0.173       \n"," val [600] loss: 3.215, Perplexity: 24.903, blue score: 0.316       \n"," val [900] loss: 3.125, Perplexity: 22.766, blue score: 0.287       \n"," val [1200] loss: 3.097, Perplexity: 22.142, blue score: 0.310       \n"," val [1500] loss: 2.940, Perplexity: 18.915, blue score: 0.350       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3pFFO7IjIZIM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592569441699,"user_tz":-480,"elapsed":1745,"user":{"displayName":"Lu Tongyu","photoUrl":"","userId":"13618470284889852279"}},"outputId":"4c849306-0751-48af-8ede-a8c1a9ae769d"},"source":["train_dataset = RhythmDataset(config.data_path, config.max_output_len, 'rhythm_pattern_list_all.data')\n","train_loader = data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n","train_iter = infinite_iter(train_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["rhythm_pattern_list_all.data dataset size: 1019\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uialyivgIZ_L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1592569474630,"user_tz":-480,"elapsed":1879,"user":{"displayName":"Lu Tongyu","photoUrl":"","userId":"13618470284889852279"}},"outputId":"261b62cd-6a35-435c-e70c-a7d23b4baeb2"},"source":["sources, targets = next(train_iter)\n","print(sources)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[ 16, 285,  41, 415, 415, 149,  41, 415, 415, 149,  41, 415, 415, 149,\n","          41, 415, 415, 416, 257,  45,  43,  42, 257,  43, 149, 416, 257,  45,\n","          43,  42, 257,  43, 149,  44]], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5gNPaTPfj3O_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":621},"executionInfo":{"status":"ok","timestamp":1592569987154,"user_tz":-480,"elapsed":1141,"user":{"displayName":"Lu Tongyu","photoUrl":"","userId":"13618470284889852279"}},"outputId":"2c5f4d2b-9739-4c58-bd9c-8533993ae18c"},"source":["tokens2sentence(sources, train_loader.dataset.int2word)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['|2/4',\n","  'R1.500,N0.250,N0.250|2/4',\n","  'N0.500,N0.250,N0.250,N0.250,N0.250,N0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.250,N0.250|2/4',\n","  'N0.500,N0.500,N0.500,N0.250,N0.250|2/4',\n","  'N0.500,N0.250,N0.250,N0.250,N0.250,N0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.250,N0.250|2/4',\n","  'N0.500,N0.500,N0.500,N0.250,N0.250|2/4',\n","  'N0.500,N0.250,N0.250,N0.250,N0.250,N0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.250,N0.250|2/4',\n","  'N0.500,N0.500,N0.500,N0.250,N0.250|2/4',\n","  'N0.500,N0.250,N0.250,N0.250,N0.250,N0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.500|2/4',\n","  'N1.000,N1.000|2/4',\n","  'N0.250,N0.250,N0.250,N0.250,N0.500,N0.500|2/4',\n","  'N0.250,N0.250,N0.250,N0.250,N0.500,N0.250,N0.250|2/4',\n","  'N0.250,N0.250,N0.250,N0.250,N1.000|2/4',\n","  'N1.000,N1.000|2/4',\n","  'N0.250,N0.250,N0.250,N0.250,N0.500,N0.250,N0.250|2/4',\n","  'N0.500,N0.500,N0.500,N0.250,N0.250|2/4',\n","  'N0.500,N1.000,R0.500|2/4',\n","  'N1.000,N1.000|2/4',\n","  'N0.250,N0.250,N0.250,N0.250,N0.500,N0.500|2/4',\n","  'N0.250,N0.250,N0.250,N0.250,N0.500,N0.250,N0.250|2/4',\n","  'N0.250,N0.250,N0.250,N0.250,N1.000|2/4',\n","  'N1.000,N1.000|2/4',\n","  'N0.250,N0.250,N0.250,N0.250,N0.500,N0.250,N0.250|2/4',\n","  'N0.500,N0.500,N0.500,N0.250,N0.250|2/4',\n","  'N0.500,N0.500,N1.000|2/4']]"]},"metadata":{"tags":[]},"execution_count":48}]}]}